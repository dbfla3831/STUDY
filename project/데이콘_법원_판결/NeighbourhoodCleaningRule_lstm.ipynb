{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca94ce9d",
   "metadata": {},
   "source": [
    "# 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77213fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T05:04:32.453532Z",
     "start_time": "2024-03-17T05:04:32.450842Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install -U imbalanced-learn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814f548f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T06:18:03.135847Z",
     "start_time": "2024-03-18T06:18:03.128722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\mit005\\AppData\\Local\\Temp\\ipykernel_12004\\2684078333.py\", line 15, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1138, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1078, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1504, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1473, in _get_spec\n",
      "TypeError: 'frame' object is not callable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1114, in get_records\n",
      "    style = get_style_by_name(self._tb_highlight_style)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\pygments\\styles\\__init__.py\", line 89, in get_style_by_name\n",
      "    mod = __import__('pygments.styles.' + mod, None, None, [cls])\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1138, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1078, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1504, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1473, in _get_spec\n",
      "TypeError: 'frame' object is not callable\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer # 표준 토큰화\n",
    "from nltk.corpus import stopwords # 불용어 제거\n",
    "from nltk.stem import WordNetLemmatizer # 기본 형태로 변환\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule # 비대칭이라 사용\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f21329",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb5a900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T06:18:09.451094Z",
     "start_time": "2024-03-18T06:18:09.441010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\mit005\\AppData\\Local\\Temp\\ipykernel_12004\\1359571154.py\", line 1, in <module>\n",
      "    train_df = pd.read_csv('./data/train.csv')\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 912, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 577, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1407, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1661, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "                   ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py\", line 707, in get_handle\n",
      "    if _is_binary_mode(path_or_buf, mode) and \"b\" not in mode:\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py\", line 1167, in _is_binary_mode\n",
      "    return isinstance(handle, _get_binary_io_classes()) or \"b\" in getattr(\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py\", line 1182, in _get_binary_io_classes\n",
      "    zstd = import_optional_dependency(\"zstandard\", errors=\"ignore\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py\", line 142, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1138, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1078, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1504, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1473, in _get_spec\n",
      "TypeError: 'frame' object is not callable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1114, in get_records\n",
      "    style = get_style_by_name(self._tb_highlight_style)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mit005\\anaconda3\\Lib\\site-packages\\pygments\\styles\\__init__.py\", line 89, in get_style_by_name\n",
      "    mod = __import__('pygments.styles.' + mod, None, None, [cls])\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1138, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1078, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1504, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1473, in _get_spec\n",
      "TypeError: 'frame' object is not callable\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "submission_df = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ebd82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T06:17:35.379920Z",
     "start_time": "2024-03-18T06:17:35.379920Z"
    }
   },
   "outputs": [],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce88281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T06:17:35.385472Z",
     "start_time": "2024-03-18T06:17:35.385472Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.groupby('first_party_winner').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce13b7f",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2411c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T06:17:35.391966Z",
     "start_time": "2024-03-18T06:17:35.391966Z"
    }
   },
   "outputs": [],
   "source": [
    "# 문자 처리\n",
    "cat_cols = ['first_party', 'second_party', 'facts']\n",
    "\n",
    "# \\b : 단어 경계, W* : 길이가 0이상이고 단어가 아닌 문자, w{1} : 길이가 1인 단어\n",
    "short_word = re.compile(r'\\W*\\b\\w{1}\\b') # 길이가 1인 단어 찾기\n",
    "tokenizer = TreebankWordTokenizer() # 단어 단위로 토큰화\n",
    "stopword = stopwords.words('english') # 불용어 리스트 가져오기\n",
    "lemmatizer = WordNetLemmatizer() # 단어의 기본 형태 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1fe9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T06:17:35.397748Z",
     "start_time": "2024-03-18T06:17:35.397748Z"
    }
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range = (1, 2)) # 출현빈도\n",
    "vec_facts = TfidfVectorizer(ngram_range = (1, 2)) # 단어토큰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621cab20",
   "metadata": {},
   "source": [
    "## 단어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229dfb19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T06:17:35.405235Z",
     "start_time": "2024-03-18T06:17:35.405235Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepro1(df, cols, short_word, tokenizer, stopword, lemmatizer):\n",
    "    first_party_lst = []\n",
    "    second_party_lst = []\n",
    "    facts_lst = []\n",
    "    \n",
    "    for col in cols:\n",
    "        df[col] = df[col].str.strip() # 공백 제거\n",
    "        df[col] = df[col].str.lower() # 소문자로 변경\n",
    "        df[col] = df[col].str.replace(',', '')\n",
    "        df[col] = df[col].str.replace('.', '')\n",
    "        \n",
    "        if col == 'first_party':\n",
    "            for content in df[col]:\n",
    "                content = short_word.sub('', content) # 한 글자 단어 제거\n",
    "                com = re.compile(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s]\") # 한글, 영어, 숫자 및 공백 문자를 제외한 모든 문자를 매칭\n",
    "                content = com.sub('', content)\n",
    "                tokens = tokenizer.tokenize(content) # 단어 토큰화\n",
    "                token_lst = []\n",
    "                for token in tokens:\n",
    "                    if token not in stopword: #불용어 제거\n",
    "                        token_lst.append(lemmatizer.lemmatize(token, 'n')) # 단어의 기본 형태 가져오기\n",
    "                first_party_lst.append(token_lst)\n",
    "            # 단어들 결합\n",
    "            for i in range(len(first_party_lst)):\n",
    "                first_party_lst[i] = ' '.join(first_party_lst[i])\n",
    "                \n",
    "        elif col == 'second_party':\n",
    "            for content in df[col]:\n",
    "                content = short_word.sub('', content) # 한 글자 단어 제거\n",
    "                com = re.compile(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s]\") # 한글, 영어, 숫자 및 공백 문자를 제외한 모든 문자를 매칭\n",
    "                content = com.sub('', content)\n",
    "                tokens = tokenizer.tokenize(content) # 단어 토큰화\n",
    "                token_lst = []\n",
    "                for token in tokens:\n",
    "                    if token not in stopword: #불용어 제거\n",
    "                        token_lst.append(lemmatizer.lemmatize(token, 'n')) # 단어의 기본 형태 가져오기\n",
    "                second_party_lst.append(token_lst)\n",
    "            # 단어들 결합\n",
    "            for i in range(len(second_party_lst)):\n",
    "                second_party_lst[i] = ' '.join(second_party_lst[i])\n",
    "                \n",
    "        elif col == 'facts':\n",
    "            for content in df[col]:\n",
    "                content = short_word.sub('', content) # 한 글자 단어 제거\n",
    "                com = re.compile(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s]\") # 한글, 영어, 숫자 및 공백 문자를 제외한 모든 문자를 매칭\n",
    "                content = com.sub('', content)\n",
    "                tokens = tokenizer.tokenize(content) # 단어 토큰화\n",
    "                token_lst = []\n",
    "                for token in tokens:\n",
    "                    if token not in stopword: #불용어 제거\n",
    "                        token_lst.append(lemmatizer.lemmatize(token, 'n')) # 단어의 기본 형태 가져오기\n",
    "                facts_lst.append(token_lst)\n",
    "            # 단어들 결합\n",
    "            for i in range(len(facts_lst)):\n",
    "                facts_lst[i] = ' '.join(facts_lst[i])\n",
    "                \n",
    "    return first_party_lst, second_party_lst, facts_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fdbaff",
   "metadata": {},
   "source": [
    "## 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52331c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T06:17:35.411218Z",
     "start_time": "2024-03-18T06:17:35.411218Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepro2(first, second, facts, vec, vec_facts, is_train):\n",
    "    if is_train:\n",
    "        vec.fit(first + second) # conut\n",
    "        vec_facts.fit(facts) # Tf\n",
    "    \n",
    "    X_first = vec.transform(first).toarray()\n",
    "    X_second = vec.transform(first).toarray()\n",
    "    X_facts = vec_facts.transform(facts).toarray()\n",
    "    \n",
    "    return np.concatenate([X_first, X_second, X_facts], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb8efb",
   "metadata": {},
   "source": [
    "전처리 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9711d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T06:17:35.417803Z",
     "start_time": "2024-03-18T06:17:35.417803Z"
    }
   },
   "outputs": [],
   "source": [
    "train_first, train_second, train_facts = prepro1(train_df, cat_cols, short_word, tokenizer, stopword, lemmatizer)\n",
    "test_first, test_second, test_facts = prepro1(test_df, cat_cols, short_word, tokenizer, stopword, lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a68025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T06:17:35.423309Z",
     "start_time": "2024-03-18T06:17:35.423309Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = prepro2(train_first, train_second, train_facts, vec, vec_facts, True)\n",
    "y_train = train_df['first_party_winner']\n",
    "X_test = prepro2(test_first, test_second, test_facts, vec, vec_facts, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778097f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T06:17:35.430295Z",
     "start_time": "2024-03-18T06:17:35.429299Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Train shape : {}, {}'.format(X_train.shape, y_train.shape))\n",
    "print('Test shape : {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054c404",
   "metadata": {},
   "source": [
    "## 불균형 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987a2d5",
   "metadata": {},
   "source": [
    "NeighbourhoodCleaningRule\n",
    "\n",
    "- 불균형한 데이터셋에서 소수 클래스의 근접한 이웃을 고려하여 데이터를 정제하는 언더 샘플링 기법 중 하나\n",
    "\n",
    "1. 소수 클래스의 샘플을 중심으로 주변 이웃들을 찾는다\n",
    "\n",
    "2. 이웃들 중에서 다수 클래스에 속한 샘플들을 제거한다\n",
    "\n",
    "3. 이렇게 제거된 샘플들을 제외하고 남은 샘플들을 반환한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dca5158e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:31.393678Z",
     "start_time": "2024-03-17T06:18:14.831691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_neighbourhood_cleaning_rule.py:201: FutureWarning: `kind_sel` is deprecated in 0.12 and will be removed in 0.14. It already has not effect and corresponds to the `'all'` option.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (1775, 204261), (1775,)\n"
     ]
    }
   ],
   "source": [
    "X_ncr, y_ncr = NeighbourhoodCleaningRule(kind_sel = \"all\",  n_neighbors = 5).fit_resample(X_train, y_train)\n",
    "print('train shape : {}, {}'.format(X_ncr.shape, y_ncr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc56643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:31.400475Z",
     "start_time": "2024-03-17T06:18:31.394672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_party_winner\n",
       "1    946\n",
       "0    829\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ncr.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee94189",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62232246",
   "metadata": {},
   "source": [
    "## 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec92e12",
   "metadata": {},
   "source": [
    "train데이터 셋으로 train, val 데이터 셋으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb7cb7cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:32.165691Z",
     "start_time": "2024-03-17T06:18:31.401471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (1420, 204261), (1420,)\n",
      "first_party_winner\n",
      "1    757\n",
      "0    663\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation shape : (355, 204261), (355,)\n",
      "first_party_winner\n",
      "1    189\n",
      "0    166\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_ncr, y_ncr, random_state = 42, test_size = 0.2, \n",
    "                                                 stratify = y_ncr)\n",
    "\n",
    "print('Train shape : {}, {}'.format(X_train.shape, y_train.shape))\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print()\n",
    "\n",
    "print('Validation shape : {}, {}'.format(X_val.shape, y_val.shape))\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c50b26d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:45.962887Z",
     "start_time": "2024-03-17T06:18:32.166686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_1/lstm_1/TensorArrayUnstack/TensorListFromTensor defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16664\\3074745910.py\", line 23, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 323, in fit\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 105, in one_step_on_data\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 56, in train_step\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 203, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 188, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 153, in _run_through_graph\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 572, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 538, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 397, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 533, in inner_loop\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 339, in inner_loop\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 246, in rnn\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 248, in <genexpr>\n\nOOM when allocating tensor with shape[64,100] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node sequential_1/lstm_1/TensorArrayUnstack/TensorListFromTensor}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_3016]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node sequential_1/lstm_1/TensorArrayUnstack/TensorListFromTensor defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16664\\3074745910.py\", line 23, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 323, in fit\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 105, in one_step_on_data\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 56, in train_step\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 203, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 188, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 153, in _run_through_graph\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 572, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 538, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 397, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 533, in inner_loop\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 339, in inner_loop\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 246, in rnn\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 248, in <genexpr>\n\nOOM when allocating tensor with shape[64,100] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node sequential_1/lstm_1/TensorArrayUnstack/TensorListFromTensor}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_3016]"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "vocab_size = 10000\n",
    "embedding_dim = 100\n",
    "\n",
    "# 임베딩 레이어 추가\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "\n",
    "# LSTM 레이어 추가 (return_sequences=False로 설정)\n",
    "model.add(LSTM(units=64))\n",
    "\n",
    "# Dense 레이어 추가\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# 출력 레이어 추가\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b6d3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91829fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9029e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d70e0ff",
   "metadata": {},
   "source": [
    "# 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ba43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred  = best_logistic.predict(X_test)\n",
    "# submission_df['first_party_winner'] = y_pred\n",
    "# submission_df.to_csv('neighbourhoodcleaningrule_logi.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e716e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
