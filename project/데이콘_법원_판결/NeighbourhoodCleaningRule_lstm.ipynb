{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca94ce9d",
   "metadata": {},
   "source": [
    "# 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77213fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T05:04:32.453532Z",
     "start_time": "2024-03-17T05:04:32.450842Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install -U imbalanced-learn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814f548f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:06.890659Z",
     "start_time": "2024-03-17T06:18:01.492059Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer # 표준 토큰화\n",
    "from nltk.corpus import stopwords # 불용어 제거\n",
    "from nltk.stem import WordNetLemmatizer # 기본 형태로 변환\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule # 비대칭이라 사용\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f21329",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb5a900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:06.938664Z",
     "start_time": "2024-03-17T06:18:06.891653Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "submission_df = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "933ebd82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:06.951968Z",
     "start_time": "2024-03-17T06:18:06.939683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>Phil A. St. Amant</td>\n",
       "      <td>Herman A. Thompson</td>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Stephen Duncan</td>\n",
       "      <td>Lawrence Owens</td>\n",
       "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>Billy Joe Magwood</td>\n",
       "      <td>Tony Patterson, Warden, et al.</td>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Linkletter</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Victor Linkletter was convicted in state court...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>William Earl Fikes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID         first_party                    second_party  \\\n",
       "0  TRAIN_0000   Phil A. St. Amant              Herman A. Thompson   \n",
       "1  TRAIN_0001      Stephen Duncan                  Lawrence Owens   \n",
       "2  TRAIN_0002   Billy Joe Magwood  Tony Patterson, Warden, et al.   \n",
       "3  TRAIN_0003          Linkletter                          Walker   \n",
       "4  TRAIN_0004  William Earl Fikes                         Alabama   \n",
       "\n",
       "                                               facts  first_party_winner  \n",
       "0  On June 27, 1962, Phil St. Amant, a candidate ...                   1  \n",
       "1  Ramon Nelson was riding his bike when he suffe...                   0  \n",
       "2  An Alabama state court convicted Billy Joe Mag...                   1  \n",
       "3  Victor Linkletter was convicted in state court...                   0  \n",
       "4  On April 24, 1953 in Selma, Alabama, an intrud...                   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>Salerno</td>\n",
       "      <td>United States</td>\n",
       "      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>Milberg Weiss Bershad Hynes and Lerach</td>\n",
       "      <td>Lexecon, Inc.</td>\n",
       "      <td>Lexecon Inc. was a defendant in a class action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>No. 07-582\\t Title: \\t Federal Communications ...</td>\n",
       "      <td>Fox Television Stations, Inc., et al.</td>\n",
       "      <td>In 2002 and 2003, Fox Television Stations broa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>Harold Kaufman</td>\n",
       "      <td>United States</td>\n",
       "      <td>During his trial for armed robbery of a federa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>Berger</td>\n",
       "      <td>Hanlon</td>\n",
       "      <td>In 1993, a magistrate judge issued a warrant a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                        first_party  \\\n",
       "0  TEST_0000                                            Salerno   \n",
       "1  TEST_0001             Milberg Weiss Bershad Hynes and Lerach   \n",
       "2  TEST_0002  No. 07-582\\t Title: \\t Federal Communications ...   \n",
       "3  TEST_0003                                    Harold Kaufman    \n",
       "4  TEST_0004                                             Berger   \n",
       "\n",
       "                            second_party  \\\n",
       "0                          United States   \n",
       "1                          Lexecon, Inc.   \n",
       "2  Fox Television Stations, Inc., et al.   \n",
       "3                          United States   \n",
       "4                                 Hanlon   \n",
       "\n",
       "                                               facts  \n",
       "0  The 1984 Bail Reform Act allowed the federal c...  \n",
       "1  Lexecon Inc. was a defendant in a class action...  \n",
       "2  In 2002 and 2003, Fox Television Stations broa...  \n",
       "3  During his trial for armed robbery of a federa...  \n",
       "4  In 1993, a magistrate judge issued a warrant a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce88281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:06.957673Z",
     "start_time": "2024-03-17T06:18:06.952964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_party_winner\n",
       "0     829\n",
       "1    1649\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('first_party_winner').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce13b7f",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff2411c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:06.962350Z",
     "start_time": "2024-03-17T06:18:06.958669Z"
    }
   },
   "outputs": [],
   "source": [
    "# 문자 처리\n",
    "cat_cols = ['first_party', 'second_party', 'facts']\n",
    "\n",
    "# \\b : 단어 경계, W* : 길이가 0이상이고 단어가 아닌 문자, w{1} : 길이가 1인 단어\n",
    "short_word = re.compile(r'\\W*\\b\\w{1}\\b') # 길이가 1인 단어 찾기\n",
    "tokenizer = TreebankWordTokenizer() # 단어 단위로 토큰화\n",
    "stopword = stopwords.words('english') # 불용어 리스트 가져오기\n",
    "lemmatizer = WordNetLemmatizer() # 단어의 기본 형태 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a1fe9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:06.965408Z",
     "start_time": "2024-03-17T06:18:06.963331Z"
    }
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range = (1, 2)) # 출현빈도\n",
    "vec_facts = TfidfVectorizer(ngram_range = (1, 2)) # 단어토큰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621cab20",
   "metadata": {},
   "source": [
    "## 단어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "229dfb19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:06.974383Z",
     "start_time": "2024-03-17T06:18:06.966404Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepro1(df, cols, short_word, tokenizer, stopword, lemmatizer):\n",
    "    first_party_lst = []\n",
    "    second_party_lst = []\n",
    "    facts_lst = []\n",
    "    \n",
    "    for col in cols:\n",
    "        df[col] = df[col].str.strip() # 공백 제거\n",
    "        df[col] = df[col].str.lower() # 소문자로 변경\n",
    "        df[col] = df[col].str.replace(',', '')\n",
    "        df[col] = df[col].str.replace('.', '')\n",
    "        \n",
    "        if col == 'first_party':\n",
    "            for content in df[col]:\n",
    "                content = short_word.sub('', content) # 한 글자 단어 제거\n",
    "                com = re.compile(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s]\") # 한글, 영어, 숫자 및 공백 문자를 제외한 모든 문자를 매칭\n",
    "                content = com.sub('', content)\n",
    "                tokens = tokenizer.tokenize(content) # 단어 토큰화\n",
    "                token_lst = []\n",
    "                for token in tokens:\n",
    "                    if token not in stopword: #불용어 제거\n",
    "                        token_lst.append(lemmatizer.lemmatize(token, 'n')) # 단어의 기본 형태 가져오기\n",
    "                first_party_lst.append(token_lst)\n",
    "            # 단어들 결합\n",
    "            for i in range(len(first_party_lst)):\n",
    "                first_party_lst[i] = ' '.join(first_party_lst[i])\n",
    "                \n",
    "        elif col == 'second_party':\n",
    "            for content in df[col]:\n",
    "                content = short_word.sub('', content) # 한 글자 단어 제거\n",
    "                com = re.compile(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s]\") # 한글, 영어, 숫자 및 공백 문자를 제외한 모든 문자를 매칭\n",
    "                content = com.sub('', content)\n",
    "                tokens = tokenizer.tokenize(content) # 단어 토큰화\n",
    "                token_lst = []\n",
    "                for token in tokens:\n",
    "                    if token not in stopword: #불용어 제거\n",
    "                        token_lst.append(lemmatizer.lemmatize(token, 'n')) # 단어의 기본 형태 가져오기\n",
    "                second_party_lst.append(token_lst)\n",
    "            # 단어들 결합\n",
    "            for i in range(len(second_party_lst)):\n",
    "                second_party_lst[i] = ' '.join(second_party_lst[i])\n",
    "                \n",
    "        elif col == 'facts':\n",
    "            for content in df[col]:\n",
    "                content = short_word.sub('', content) # 한 글자 단어 제거\n",
    "                com = re.compile(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s]\") # 한글, 영어, 숫자 및 공백 문자를 제외한 모든 문자를 매칭\n",
    "                content = com.sub('', content)\n",
    "                tokens = tokenizer.tokenize(content) # 단어 토큰화\n",
    "                token_lst = []\n",
    "                for token in tokens:\n",
    "                    if token not in stopword: #불용어 제거\n",
    "                        token_lst.append(lemmatizer.lemmatize(token, 'n')) # 단어의 기본 형태 가져오기\n",
    "                facts_lst.append(token_lst)\n",
    "            # 단어들 결합\n",
    "            for i in range(len(facts_lst)):\n",
    "                facts_lst[i] = ' '.join(facts_lst[i])\n",
    "                \n",
    "    return first_party_lst, second_party_lst, facts_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fdbaff",
   "metadata": {},
   "source": [
    "## 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52331c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:06.978362Z",
     "start_time": "2024-03-17T06:18:06.975379Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepro2(first, second, facts, vec, vec_facts, is_train):\n",
    "    if is_train:\n",
    "        vec.fit(first + second) # conut\n",
    "        vec_facts.fit(facts) # Tf\n",
    "    \n",
    "    X_first = vec.transform(first).toarray()\n",
    "    X_second = vec.transform(first).toarray()\n",
    "    X_facts = vec_facts.transform(facts).toarray()\n",
    "    \n",
    "    return np.concatenate([X_first, X_second, X_facts], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb8efb",
   "metadata": {},
   "source": [
    "전처리 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9711d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:11.279209Z",
     "start_time": "2024-03-17T06:18:06.979358Z"
    }
   },
   "outputs": [],
   "source": [
    "train_first, train_second, train_facts = prepro1(train_df, cat_cols, short_word, tokenizer, stopword, lemmatizer)\n",
    "test_first, test_second, test_facts = prepro1(test_df, cat_cols, short_word, tokenizer, stopword, lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a68025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:14.826691Z",
     "start_time": "2024-03-17T06:18:11.280766Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = prepro2(train_first, train_second, train_facts, vec, vec_facts, True)\n",
    "y_train = train_df['first_party_winner']\n",
    "X_test = prepro2(test_first, test_second, test_facts, vec, vec_facts, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "778097f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:14.830694Z",
     "start_time": "2024-03-17T06:18:14.827684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (2478, 204261), (2478,)\n",
      "Test shape : (1240, 204261)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape : {}, {}'.format(X_train.shape, y_train.shape))\n",
    "print('Test shape : {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054c404",
   "metadata": {},
   "source": [
    "## 불균형 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987a2d5",
   "metadata": {},
   "source": [
    "NeighbourhoodCleaningRule\n",
    "\n",
    "- 불균형한 데이터셋에서 소수 클래스의 근접한 이웃을 고려하여 데이터를 정제하는 언더 샘플링 기법 중 하나\n",
    "\n",
    "1. 소수 클래스의 샘플을 중심으로 주변 이웃들을 찾는다\n",
    "\n",
    "2. 이웃들 중에서 다수 클래스에 속한 샘플들을 제거한다\n",
    "\n",
    "3. 이렇게 제거된 샘플들을 제외하고 남은 샘플들을 반환한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dca5158e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:31.393678Z",
     "start_time": "2024-03-17T06:18:14.831691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_neighbourhood_cleaning_rule.py:201: FutureWarning: `kind_sel` is deprecated in 0.12 and will be removed in 0.14. It already has not effect and corresponds to the `'all'` option.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (1775, 204261), (1775,)\n"
     ]
    }
   ],
   "source": [
    "X_ncr, y_ncr = NeighbourhoodCleaningRule(kind_sel = \"all\",  n_neighbors = 5).fit_resample(X_train, y_train)\n",
    "print('train shape : {}, {}'.format(X_ncr.shape, y_ncr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc56643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:31.400475Z",
     "start_time": "2024-03-17T06:18:31.394672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_party_winner\n",
       "1    946\n",
       "0    829\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ncr.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee94189",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62232246",
   "metadata": {},
   "source": [
    "## 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec92e12",
   "metadata": {},
   "source": [
    "train데이터 셋으로 train, val 데이터 셋으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb7cb7cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:32.165691Z",
     "start_time": "2024-03-17T06:18:31.401471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (1420, 204261), (1420,)\n",
      "first_party_winner\n",
      "1    757\n",
      "0    663\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation shape : (355, 204261), (355,)\n",
      "first_party_winner\n",
      "1    189\n",
      "0    166\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_ncr, y_ncr, random_state = 42, test_size = 0.2, \n",
    "                                                 stratify = y_ncr)\n",
    "\n",
    "print('Train shape : {}, {}'.format(X_train.shape, y_train.shape))\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print()\n",
    "\n",
    "print('Validation shape : {}, {}'.format(X_val.shape, y_val.shape))\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c50b26d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-17T06:18:45.962887Z",
     "start_time": "2024-03-17T06:18:32.166686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_1/lstm_1/TensorArrayUnstack/TensorListFromTensor defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16664\\3074745910.py\", line 23, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 323, in fit\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 105, in one_step_on_data\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 56, in train_step\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 203, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 188, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 153, in _run_through_graph\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 572, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 538, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 397, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 533, in inner_loop\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 339, in inner_loop\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 246, in rnn\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 248, in <genexpr>\n\nOOM when allocating tensor with shape[64,100] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node sequential_1/lstm_1/TensorArrayUnstack/TensorListFromTensor}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_3016]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node sequential_1/lstm_1/TensorArrayUnstack/TensorListFromTensor defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16664\\3074745910.py\", line 23, in <module>\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 323, in fit\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 117, in one_step_on_iterator\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 105, in one_step_on_data\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 56, in train_step\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 203, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 188, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 153, in _run_through_graph\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 572, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 816, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 118, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 42, in __call__\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 157, in error_handler\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 538, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 397, in call\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py\", line 533, in inner_loop\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py\", line 339, in inner_loop\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 246, in rnn\n\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\rnn.py\", line 248, in <genexpr>\n\nOOM when allocating tensor with shape[64,100] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node sequential_1/lstm_1/TensorArrayUnstack/TensorListFromTensor}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_3016]"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "vocab_size = 10000\n",
    "embedding_dim = 100\n",
    "\n",
    "# 임베딩 레이어 추가\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "\n",
    "# LSTM 레이어 추가 (return_sequences=False로 설정)\n",
    "model.add(LSTM(units=64))\n",
    "\n",
    "# Dense 레이어 추가\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# 출력 레이어 추가\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b6d3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91829fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9029e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d70e0ff",
   "metadata": {},
   "source": [
    "# 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ba43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred  = best_logistic.predict(X_test)\n",
    "# submission_df['first_party_winner'] = y_pred\n",
    "# submission_df.to_csv('neighbourhoodcleaningrule_logi.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e716e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
