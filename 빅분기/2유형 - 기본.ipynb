{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WvdNmWky5UI"
   },
   "source": [
    "# one-hot-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3574,
     "status": "ok",
     "timestamp": 1701177496338,
     "user": {
      "displayName": "김유림",
      "userId": "09242611142827377637"
     },
     "user_tz": -540
    },
    "id": "0vc_4VaoEk4m",
    "outputId": "404192ac-c113-4b1d-8fb3-52e386bd6a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ac :  0.9963285910968334\n",
      "val ac :  0.7673982869379015\n",
      "0.7594579508327265\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#데이터 로드\n",
    "x_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/HRdata/X_train.csv\")\n",
    "y_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/HRdata/y_train.csv\")\n",
    "x_test= pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/HRdata/X_test.csv\")\n",
    "\n",
    "col_drop = ['enrollee_id', 'city', 'experience']\n",
    "col_num = ['city_development_index', 'training_hours']\n",
    "col_cat = list(set(x_train.columns) - set(col_drop) - set(col_num))\n",
    "\n",
    "x_test_id = x_test['enrollee_id']\n",
    "\n",
    "x_train = x_train.drop(col_drop, axis = 1)\n",
    "x_test = x_test.drop(col_drop, axis = 1)\n",
    "y_train = y_train['target']\n",
    "\n",
    "# 명목형\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = pd.concat([x_train, x_test])\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown = 'ignore')\n",
    "ohe.fit(X[col_cat])\n",
    "\n",
    "x_train_res = ohe.transform(x_train[col_cat])\n",
    "x_test_res = ohe.transform(x_test[col_cat])\n",
    "\n",
    "x_train_ohe = pd.DataFrame(x_train_res.todense(), columns = ohe.get_feature_names_out())\n",
    "x_test_ohe = pd.DataFrame(x_test_res.todense(), columns = ohe.get_feature_names_out())\n",
    "\n",
    "\n",
    "x_train_fin = pd.concat([x_train_ohe, x_train[col_num]], axis = 1)\n",
    "x_test_fin = pd.concat([x_test_ohe, x_test[col_num]], axis = 1)\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train_fin, y_train.values.ravel(), test_size = 0.3)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_tr[col_num])\n",
    "\n",
    "x_tr[col_num] = scaler.transform(x_tr[col_num])\n",
    "x_val[col_num] = scaler.transform(x_val[col_num])\n",
    "x_test_fin[col_num] = scaler.transform(x_test_fin[col_num])\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_tr, y_tr)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_tr_pred = model.predict(x_tr)\n",
    "y_val_pred = model.predict(x_val)\n",
    "\n",
    "print('train ac : ', accuracy_score(y_tr_pred, y_tr))\n",
    "print('val ac : ', accuracy_score(y_val_pred, y_val))\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_val_pred_probd = model.predict_proba(x_val)[:,1]\n",
    "print(roc_auc_score(y_val, y_val_pred_probd))\n",
    "\n",
    "y_pred = model.predict(x_test_fin)\n",
    "result = pd.DataFrame({'enrollee_id' : x_test_id, 'target' : y_pred})\n",
    "result.to_csv('0030.csv', index = False)\n",
    "\n",
    "# 학률\n",
    "# y_pred = model.predict_proba(x_test_dum)[:, 1]\n",
    "# result = pd.DataFrame({'enrollee_id' : x_test_id, 'target' : y_pred})\n",
    "# result.to_csv('0030.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTNsXdZ_zGdG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#데이터 로드\n",
    "x_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/MedicalCost/x_train.csv\")\n",
    "y_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/MedicalCost/y_train.csv\")\n",
    "x_test= pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/MedicalCost/x_test.csv\")\n",
    "\n",
    "col_drop = ['ID']\n",
    "col_num = ['age', 'bmi', 'children']\n",
    "col_cat = ['sex', 'smoker', 'region']\n",
    "test_id = x_test['ID']\n",
    "\n",
    "x_train = x_train.drop(col_drop, axis = 1)\n",
    "x_test = x_test.drop(col_drop, axis = 1)\n",
    "y_train = y_train.drop(col_drop, axis = 1)\n",
    "\n",
    "# ohe\n",
    "x = pd.concat([x_train, x_test])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(handle_unknown = 'ignore')\n",
    "ohe.fit(x[col_cat])\n",
    "\n",
    "x_train_res = ohe.transform(x_train[col_cat])\n",
    "x_test_res = ohe.transform(x_test[col_cat])\n",
    "\n",
    "x_train_ohe = pd.DataFrame(x_train_res.todense(), columns = ohe.get_feature_names_out())\n",
    "x_test_ohe = pd.DataFrame(x_test_res.todense(), columns = ohe.get_feature_names_out())\n",
    "\n",
    "x_train_fin = pd.concat([x_train_ohe, x_train[col_num]], axis = 1)\n",
    "x_test_fin = pd.concat([x_test_ohe, x_test[col_num]], axis = 1)\n",
    "\n",
    "# split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train_fin, y_train.values.ravel(), test_size = 0.3)\n",
    "\n",
    "#scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_tr[col_num])\n",
    "\n",
    "x_tr[col_num] = scaler.transform(x_tr[col_num])\n",
    "x_val[col_num] = scaler.transform(x_val[col_num])\n",
    "x_test_fin[col_num] = scaler.transform(x_test_fin[col_num])\n",
    "\n",
    "# model\n",
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor()\n",
    "model.fit(x_tr, y_tr)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error , mean_absolute_percentage_error ,r2_score\n",
    "y_tr_pred = model.predict(x_tr)\n",
    "y_val_pred = model.predict(x_val)\n",
    "\n",
    "print('tr mse : ', mean_squared_error(y_tr, y_tr_pred))\n",
    "print('val mse : ', mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "print('tr rmse : ', mean_squared_error(y_tr, y_tr_pred, squared = False))\n",
    "print('val rmse : ', mean_squared_error(y_val, y_val_pred, squared = False))\n",
    "\n",
    "print('tr mae : ', mean_absolute_error(y_tr, y_tr_pred))\n",
    "print('val mae : ', mean_absolute_error(y_val, y_val_pred))\n",
    "\n",
    "print('tr mspe : ', mean_absolute_percentage_error(y_tr, y_tr_pred))\n",
    "print('val mspe : ', mean_absolute_percentage_error(y_val, y_val_pred))\n",
    "\n",
    "print('tr r2 : ', mean_squared_error(y_tr, y_tr_pred))\n",
    "print('val r2 : ', mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "print('tr mse : ', r2_score(y_tr, y_tr_pred))\n",
    "print('val mse : ', r2_score(y_val, y_val_pred))\n",
    "\n",
    "y_pred = model.predict(x_test_fin)\n",
    "result = pd.DataFrame({'ID' : test_id, 'charges' : y_pred})\n",
    "result.to_csv('00300.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erMQ13H7y8L9"
   },
   "source": [
    "# col이 다른 dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UWr7tLky_st"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#데이터 로드\n",
    "x_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/carsprice/X_train.csv\")\n",
    "y_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/carsprice/y_train.csv\")\n",
    "x_test= pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/carsprice/X_test.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# col drop, null, 이상치, object\n",
    "drop_col = ['carID']\n",
    "col_num = ['year', 'mileage', 'tax', 'mpg', 'engineSize']\n",
    "col_cat = ['brand', 'model', 'transmission', 'mileage', 'fuelType']\n",
    "y_col = ['price']\n",
    "x_test_copy = x_test.copy()\n",
    "\n",
    "x_train = x_train.drop(drop_col, axis = 1)\n",
    "x_test = x_test.drop(drop_col, axis = 1)\n",
    "y_train = y_train[y_col]\n",
    "\n",
    "# object -> num\n",
    "dum_col = ['brand', 'transmission', 'fuelType']\n",
    "\n",
    "X_train_dum = pd.get_dummies(x_train[dum_col])\n",
    "X_test_dum = pd.get_dummies(x_test[dum_col])\n",
    "\n",
    "train_cols = set(X_train_dum.columns)\n",
    "test_cols = set(X_test_dum.columns)\n",
    "\n",
    "missing_in_test = train_cols - test_cols\n",
    "for col in missing_in_test:\n",
    "    X_test_dum[col] = 0\n",
    "\n",
    "missing_in_train = test_cols - train_cols\n",
    "for col in missing_in_train:\n",
    "    X_train_dum[col] = 0\n",
    "\n",
    "X_test_dum = X_test_dum[X_train_dum.columns]\n",
    "\n",
    "\n",
    "x_train_fin = pd.concat([X_train_dum, x_train[col_num]], axis = 1)\n",
    "x_test_fin = pd.concat([X_test_dum, x_test[col_num]], axis = 1)\n",
    "\n",
    "\n",
    "# split, scaler,model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train_fin, y_train.values.ravel(), test_size = 0.3)\n",
    "\n",
    "# scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_tr[col_num])\n",
    "\n",
    "x_tr[col_num] = scaler.transform(x_tr[col_num])\n",
    "x_val[col_num] = scaler.transform(x_val[col_num])\n",
    "x_test_fin[col_num] = scaler.transform(x_test_fin[col_num])\n",
    "\n",
    "# model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_tr, y_tr)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "y_val_pred = model.predict(x_val)\n",
    "print(r2_score(y_val, y_val_pred))\n",
    "\n",
    "# 평가\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(x_test_fin)\n",
    "pd.DataFrame({'carID' : x_test_copy['carID'],'price' : y_pred}).to_csv('00030.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiPkjZnizcz_"
   },
   "source": [
    "# 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KX4CQZYQzcY5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/krdatacertificate/e4_p2_train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/krdatacertificate/e4_p2_test.csv')\n",
    "\n",
    "## 명목형 nan -> 가장 많이 나온 값을 넣기(.value_counts().sort_index(ascending = False).index[0])\n",
    "## 수치형 nan -> 평균 넣기\n",
    "## train nan처리\n",
    "train['Ever_Married'] = train['Ever_Married'].fillna(train['Ever_Married'].value_counts().sort_values(ascending = False).index[0])\n",
    "train['Graduated'] = train['Graduated'].fillna(train['Graduated'].value_counts().sort_values(ascending = False).index[0])\n",
    "train['Profession'] = train['Profession'].fillna(train['Profession'].value_counts().sort_values(ascending = False).index[0])\n",
    "train['Work_Experience'] = train['Work_Experience'].fillna(train['Work_Experience'].mean())\n",
    "train['Family_Size'] = train['Family_Size'].fillna(train['Family_Size'].mean())\n",
    "train['Var_1'] = train['Var_1'].fillna(train['Var_1'].value_counts().sort_values(ascending = False).index[0])\n",
    "\n",
    "## test nan 처리\n",
    "test['Ever_Married'] = test['Ever_Married'].fillna(test['Ever_Married'].value_counts().sort_values(ascending = False).index[0])\n",
    "test['Graduated'] = test['Graduated'].fillna(test['Graduated'].value_counts().sort_values(ascending = False).index[0])\n",
    "test['Profession'] = test['Profession'].fillna(test['Profession'].value_counts().sort_values(ascending = False).index[0])\n",
    "test['Work_Experience'] = test['Work_Experience'].fillna(test['Work_Experience'].mean())\n",
    "test['Family_Size'] = test['Family_Size'].fillna(test['Family_Size'].mean())\n",
    "test['Var_1'] = test['Var_1'].fillna(test['Var_1'].value_counts().sort_values(ascending = False).index[0])\n",
    "\n",
    "\n",
    "col_drop = ['ID']\n",
    "col_num = ['Age', 'Work_Experience', 'Family_Size']\n",
    "col_cat = ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1']\n",
    "col_y = ['Segmentation']\n",
    "\n",
    "train = train.drop(col_drop, axis = 1)\n",
    "test = test.drop(col_drop, axis = 1)\n",
    "x_train = train.loc[:, 'Gender' : 'Var_1']\n",
    "y_train = train[col_y]\n",
    "x_test = test\n",
    "\n",
    "# 명목형\n",
    "ohe_col = ['Gender', 'Ever_Married', 'Graduated', 'Spending_Score']\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "x = pd.concat([x_train, x_test])\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown = 'ignore')\n",
    "ohe.fit(x[ohe_col])\n",
    "\n",
    "x_train_res = ohe.transform(x_train[ohe_col])\n",
    "x_test_res = ohe.transform(x_test[ohe_col])\n",
    "\n",
    "x_train_ohe = pd.DataFrame(x_train_res.todense(), columns = ohe.get_feature_names_out())\n",
    "x_test_ohe = pd.DataFrame(x_test_res.todense(), columns = ohe.get_feature_names_out())\n",
    "\n",
    "x_train_fin = pd.concat([x_train_ohe, x_train[col_num]], axis = 1)\n",
    "x_test_fin = pd.concat([x_test_ohe, x_test[col_num]], axis = 1)\n",
    "\n",
    "# split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train_fin, y_train.values.ravel(), test_size = 0.3, stratify = y_train.values.ravel())\n",
    "\n",
    "# scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_tr[col_num])\n",
    "\n",
    "x_tr[col_num] = scaler.transform(x_tr[col_num])\n",
    "x_val[col_num] = scaler.transform(x_val[col_num])\n",
    "x_test_fin[col_num] = scaler.transform(x_test[col_num])\n",
    "\n",
    "#model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_tr, y_tr)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_train = model.predict(x_tr)\n",
    "print('train as : ', accuracy_score(y_pred_train, y_tr))\n",
    "\n",
    "y_pred_val = model.predict(x_val)\n",
    "print('val as : ', accuracy_score(y_pred_val, y_val))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred_train = model.predict(x_tr)\n",
    "print('train f1 : ', f1_score(y_tr, y_pred_train, average = 'macro'))\n",
    "\n",
    "y_pred_val = model.predict(x_val)\n",
    "print('val f1 : ', f1_score(y_val, y_pred_val, average = 'macro'))\n",
    "\n",
    "# 제출\n",
    "y_pred = model.predict(x_test_fin)\n",
    "result = pd.DataFrame({'index' : x_test.index, 'Segmentation' : y_pred})\n",
    "result.to_csv('00300.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHdSiwLMy_gQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOSE73DrGbwQ4QCxZjaR4QC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.734px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
